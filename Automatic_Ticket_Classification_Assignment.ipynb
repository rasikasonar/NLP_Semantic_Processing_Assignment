{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JuLFIymAL58u"
   },
   "source": [
    "## Let us import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O-Q9pqrcJrFr"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, nltk, spacy, string\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "from plotly.offline import plot\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from pprint import pprint\n",
    "\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns=30\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtRLCsNVJrFt"
   },
   "source": [
    "## Loading the data\n",
    "\n",
    "Lets convert the json data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "puVzIf_iJrFt"
   },
   "outputs": [],
   "source": [
    "with open('complaints-2021-05-14_08_16.json', 'r') as fout:\n",
    "    f = json.load(fout)\n",
    "df=pd.json_normalize(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 78313 rows and 22 columns in the dataaset. let's analysise the data to remove duplicates and handle missing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns of the dataset are not making sense for readability, let's remove the leading underscore and 'source.' text from column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = [re.sub(\"^_\", \"\", col) for col in cols]\n",
    "new_columns = [re.sub(\"^source.\", \"\", col) for col in new_columns]\n",
    "print(new_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = new_columns\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text we are expected to process is in the complaint_what_happened column, however there are some records having blank value for this column. Let us pick only those records that are having not null value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['complaint_what_happened'] != ''].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the 87k, only 21k have the complaint column populated. The records with blank complaint column do not have any data to be analyzed, let's remove those records and use only the complaint_what_happened column for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"complaint_what_happened\"] != \"\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"complaint_what_happened\"] = df[\"complaint_what_happened\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we have any records with duplicate complaint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df[\"complaint_what_happened\"])\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total number of records with duplicate complaint are', df.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove the duplicate records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L944HZpsJrFy"
   },
   "source": [
    "## Prepare the text for topic modeling\n",
    "\n",
    "Once you have removed all the blank complaints, you need to:\n",
    "\n",
    "* Make the text lowercase\n",
    "* Remove text in square brackets\n",
    "* Remove punctuation\n",
    "* Remove words containing numbers\n",
    "\n",
    "\n",
    "Once you have done these cleaning operations you need to perform the following:\n",
    "* Lemmatize the texts\n",
    "* Extract the POS tags of the lemmatized text and remove all the words which have tags other than NN[tag == \"NN\"].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the punctuations from the data and make it lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qm7SjjSkJrFz"
   },
   "outputs": [],
   "source": [
    "def preprocess_text(complaint):\n",
    "    complaint = complaint.lower()\n",
    "    pattern = '[^\\w\\s]'\n",
    "    complaint = re.sub(pattern, '', complaint) \n",
    "    pattern = '\\w*\\d\\w*'\n",
    "    complaint = re.sub(pattern, '', complaint) \n",
    "    return complaint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.DataFrame(df['complaint_what_happened'].apply(preprocess_text))\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now lemmatize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zgOu8t8HJrFz"
   },
   "outputs": [],
   "source": [
    "def lemmatize_sentence(text):\n",
    "    sent = []\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        sent.append(token.lemma_)\n",
    "    return \" \".join(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uXnN7aa_JrF0"
   },
   "outputs": [],
   "source": [
    "df_clean['complaint_lemmatized'] = df_clean['complaint_what_happened'].apply(lemmatize_sentence)\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets remove the pos tags from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kk7fc4DuJrF1"
   },
   "outputs": [],
   "source": [
    "def pos_tag(complaint):\n",
    "    sent = []\n",
    "    blob = TextBlob(complaint)\n",
    "    sent = [word for (word,tag) in blob.tags if tag=='NN']\n",
    "    return \" \".join(sent)\n",
    "\n",
    "df_clean[\"complaint_POS_removed\"] = df_clean['complaint_lemmatized'].apply(pos_tag)\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AjxfchvFJrF2"
   },
   "outputs": [],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7Un1AElJrF2"
   },
   "source": [
    "## Exploratory data analysis to get familiar with the data.\n",
    "\n",
    "Write the code in this task to perform the following:\n",
    "\n",
    "*   Visualise the data according to the 'Complaint' character length\n",
    "*   Using a word cloud find the top 40 words by frequency among all the articles after processing the text\n",
    "*   Find the top unigrams,bigrams and trigrams by frequency among all the complaints after processing the text. â€˜\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q-zaqJF6JrF2"
   },
   "outputs": [],
   "source": [
    "char_len = [len(each_sent) for each_sent in df_clean['complaint_POS_removed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(char_len, kind='hist', bins=60)\n",
    "plt.xlabel(\"character length of complaints\")\n",
    "plt.ylabel(\"Total number of Complaints\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9jD_6SeJrF3"
   },
   "source": [
    "#### Find the top 40 words by frequency among all the articles after processing the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QcfdvtfZJrF3"
   },
   "outputs": [],
   "source": [
    "stopwords = set(STOPWORDS)\n",
    "wordcloud = WordCloud(max_font_size=60, max_words=40, \n",
    "                      background_color=\"white\", random_state=100, \n",
    "                      stopwords=stopwords).generate(str(df_clean['complaint_POS_removed']))\n",
    "plt.figure(figsize=[20,20])\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the words such as credit, card, account, bank, ticket, agent, cardmember being in the top 40 words have have occured the most in the complaints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OkSmc3UaJrF4"
   },
   "outputs": [],
   "source": [
    "df_clean['Complaint_clean'] = df_clean['complaint_POS_removed'].str.replace('-PRON-', '')\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5DfCSbbmJrF4"
   },
   "source": [
    "#### Find the top unigrams,bigrams and trigrams by frequency among all the complaints after processing the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get word / words based on ngram frequency\n",
    "def get_top_ngrams(text, n=None, ngram=(1,1)):\n",
    "    vec = CountVectorizer(stop_words='english', ngram_range=ngram).fit(text)\n",
    "    bagofwords = vec.transform(text)\n",
    "    sum_words = bagofwords.sum(axis=0)\n",
    "    words_frequency = [(word, sum_words[0, index]) for word, index in vec.vocabulary_.items()]\n",
    "    words_frequency = sorted(words_frequency, key = lambda x: x[1], reverse=True)\n",
    "    return words_frequency[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to show the words frequency\n",
    "def display_ngram_distribution(data):\n",
    "    plt.figure(figsize=[20,6])\n",
    "    sns.barplot(x=data['words'], y=data['count'])\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xlabel(\"Unigram\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(\"Count of top 30 Unigrams\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fetch the top 30 unigram words frequencies from the complaints dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5mbk5DS5JrF4"
   },
   "outputs": [],
   "source": [
    "top_30words = get_top_ngrams(df_clean['Complaint_clean'].values.astype('U'), n=30, ngram=(1,1))\n",
    "df_unigram = pd.DataFrame(top_30words, columns=['words', 'count'])\n",
    "df_unigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YX7fedm1JrF8"
   },
   "source": [
    "Top 10 words in the unigram frequency are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10 = df_unigram.sort_values(by = \"count\", ascending=False).iloc[:10]\n",
    "top_10.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_ngram_distribution(top_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us find top 30 bigram word frequencies in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aV7kD7w8JrF8"
   },
   "outputs": [],
   "source": [
    "top_30words = get_top_ngrams(df_clean['Complaint_clean'].values.astype('U'), n=30, ngram=(2,2))\n",
    "df_bigram = pd.DataFrame(top_30words, columns=['words', 'count'])\n",
    "df_bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10 = df_bigram.sort_values(by = \"count\", ascending=False).iloc[:10]\n",
    "top_10.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NPnMNIpyJrF9"
   },
   "outputs": [],
   "source": [
    "display_ngram_distribution(top_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xkh7vtbtJrF-"
   },
   "outputs": [],
   "source": [
    "top_30words = get_top_ngrams(df_clean['Complaint_clean'].values.astype('U'), n=30, ngram=(3,3))\n",
    "df_trigram = pd.DataFrame(top_30words, columns=['words', 'count'])\n",
    "df_trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "REcVxNfvJrF-"
   },
   "outputs": [],
   "source": [
    "top_10 = df_trigram.sort_values(by = \"count\", ascending=False).iloc[:10]\n",
    "top_10.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_ngram_distribution(top_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yUXzFji0JrF_"
   },
   "source": [
    "## The personal details of customer has been masked in the dataset with xxxx. Let's remove the masked text as this will be of no use for our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wKda-a_IJrF_"
   },
   "outputs": [],
   "source": [
    "df_clean['Complaint_clean'] = df_clean['Complaint_clean'].str.replace('xxxx','')\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-I0k0QtJrGA"
   },
   "source": [
    "## Feature Extraction\n",
    "Convert the raw texts to a matrix of TF-IDF features\n",
    "\n",
    "**max_df** is used for removing terms that appear too frequently, also known as \"corpus-specific stop words\"\n",
    "max_df = 0.95 means \"ignore terms that appear in more than 95% of the complaints\"\n",
    "\n",
    "**min_df** is used for removing terms that appear too infrequently\n",
    "min_df = 2 means \"ignore terms that appear in less than 2 complaints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y8fGwaCPJrGA"
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(min_df=2, max_df=0.95, stop_words='english')\n",
    "df_transformed = tfidf.fit_transform(df_clean['Complaint_clean'])\n",
    "print(df_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Q9lwvNEJrGB"
   },
   "source": [
    "## Topic Modelling using NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "amLT4omWJrGB"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sgd2A6bhJrGD"
   },
   "outputs": [],
   "source": [
    "num_topics = 5\n",
    "nmf_model = NMF(n_components=num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VPMDYbt_JrGE"
   },
   "outputs": [],
   "source": [
    "nmf_model.fit(df_transformed)\n",
    "len(tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = nmf_model.components_    # Topic-term matrix\n",
    "print(H.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "16kRfat5JrGE"
   },
   "outputs": [],
   "source": [
    "#Print the Top15 words for each of the topics\n",
    "words = np.array(tfidf.get_feature_names_out())\n",
    "topic_words = pd.DataFrame(np.zeros((num_topics, 15)), index=[f'Topic {i + 1}' for i in range(num_topics)],\n",
    "                           columns=[f'Word {i + 1}' for i in range(15)]).astype(str)\n",
    "for i in range(num_topics):\n",
    "    ix = H[i].argsort()[::-1][:15]\n",
    "    topic_words.iloc[i] = words[ix]\n",
    "\n",
    "topic_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0OIT7LmFJrGF"
   },
   "source": [
    "**From observing above table and the top 15 words being identified against the topic, we can assign below categories to the topics**\n",
    "\n",
    "- Topic 1 = Bank account services\n",
    "- Topic 2 = Credit card / Prepaid card\n",
    "- Topic 3 = Others\n",
    "- Topic 4 = Theft/Dispute reporting\n",
    "- Topic 5 = Mortgages/loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_results = nmf_model.transform(df_transformed)\n",
    "print(topic_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "peyYv-ORJrGF"
   },
   "outputs": [],
   "source": [
    "df_clean['Topic'] = topic_results.argmax(axis=1)\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aQKpufSPJrGG"
   },
   "outputs": [],
   "source": [
    "# Let's print the first 5 Complaint for each of the Topics\n",
    "df_clean_grouped=df_clean.groupby('Topic').head(5)\n",
    "df_clean_grouped.sort_values('Topic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "piyLxzj6v07j"
   },
   "source": [
    "#### After evaluating the mapping, if the topics assigned are correct then assign these names to the relevant topic:\n",
    "* Bank Account services\n",
    "* Credit card or prepaid card\n",
    "* Theft/Dispute Reporting\n",
    "* Mortgage/Loan\n",
    "* Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TWpwDG4RJrGG"
   },
   "outputs": [],
   "source": [
    "Topic_names = {  0 : \"Bank Account services\", 1: \"Credit card or prepaid card\", 2: \"Theft/Dispute Reporting\", 3: \"Mortgage/Loan\", 4: \"Others\" }\n",
    "df_clean['Topic'] = df_clean['Topic'].map(Topic_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-2ULY5K6JrGG"
   },
   "outputs": [],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Mu0QBOcJrGH"
   },
   "source": [
    "## Supervised model to predict any new complaints to the relevant Topics.\n",
    "\n",
    "You have now build the model to create the topics for each complaints.Now in the below section you will use them to classify any new complaints.\n",
    "\n",
    "Since you will be using supervised learning technique we have to convert the topic names to numbers(numpy arrays only understand numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_U8J3J8wJrGH"
   },
   "outputs": [],
   "source": [
    "Topic_names = {  \"Bank Account services\": 0, \"Credit card or prepaid card\": 1, \"Theft/Dispute Reporting\": 2, \"Mortgage/Loan\": 3, \"Others\": 4 }\n",
    "\n",
    "df_clean['Topic'] = df_clean['Topic'].map(Topic_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BWIgJUkQJrGH"
   },
   "outputs": [],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xx-FrbkWJrGH"
   },
   "outputs": [],
   "source": [
    "training_data= df_clean[[\"complaint_what_happened\",\"Topic\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lVg2pa12JrGI"
   },
   "outputs": [],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "280Vbqk-7a8M"
   },
   "source": [
    "#### Apply the supervised models on the training data created. In this process, you have to do the following:\n",
    "* Create the vector counts using Count Vectoriser\n",
    "* Transform the word vecotr to tf-idf\n",
    "* Create the train & test data using the train_test_split on the tf-idf & topics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code is to convert the sentences into a tfidf matrix which will be used as an input to the Supervised learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "X_train_cnt = vect.fit_transform(training_data['complaint_what_happened'])\n",
    "pickle.dump(vect.vocabulary_, open(\"count_vector.pk1\", \"wb\"))\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_cnt)\n",
    "pickle.dump(tfidf_transformer, open('tfidf.pk1', \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMU3vj6w-wqL"
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N2OznsObJrGP"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train_tfidf, training_data['Topic'], test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression().fit(X_train, y_train)\n",
    "logreg.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the logistic regression, we got the model accuracy of 91%. Let's save this model before going ahead with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(logreg, open(\"logreg_model.pk1\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisionTree = DecisionTreeClassifier(max_depth=6, random_state=42).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisionTree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score we are getting for Decision Tree Classifier with max_depth = 5 is 71%. Let's hypertune some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_grid = {\"max_depth\": [3,5,7,9],\n",
    "           \"min_samples_split\": [5,10,15,20,30],\n",
    "           \"min_samples_leaf\": [5,10,15,20,30]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_tuned = GridSearchCV(DecisionTreeClassifier(random_state=42),\n",
    "                                param_grid=dt_grid,\n",
    "                                cv=5,\n",
    "                                verbose=True,\n",
    "                                n_jobs=-1)\n",
    "\n",
    "decision_tree_tuned.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = decision_tree_tuned.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_modified_params = DecisionTreeClassifier(max_depth=best_params[\"max_depth\"], min_samples_leaf=best_params[\"min_samples_leaf\"], min_samples_split=best_params[\"min_samples_split\"], random_state=42).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_modified_params.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the hyperparameter tuning, we are getting the score as 76%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(decision_tree_modified_params, open(\"rf_model.pk1\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have tried both Logistic Regression and Decision Tree models with 91 & 76 percent accuracy. Let's test these models on a test sample. Here we are creating a sample sentence which will be fed to the model after converting them into tfidf matrix format. Let's see the output we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"I am getting error while using credit card at the mall. It got declined twice. I tried changing the pin at ATM but same issue occurred again\"\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now clearly above message is about a customer having issues with using credit card. The correct category for this sentence is Credit card / Prepaid card. The numeric representation for this category should be 1. Let's see the dictionary of numeric vs string categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Topic_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_complaint= np.array([sentence])\n",
    "print(sample_complaint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2 = vect.transform(sample_complaint)\n",
    "X_train_tfidf_2 = tfidf_transformer.transform(X_train_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_train_tfidf_2)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression model has correctly predicted the sentence to be of category 1 which is of category Credit card / Prepaid card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = decision_tree_modified_params.predict(X_train_tfidf_2)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the decision tree model has also predicted correct category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "T9jD_6SeJrF3",
    "5DfCSbbmJrF4",
    "yYzD85nTJrGA",
    "piyLxzj6v07j",
    "280Vbqk-7a8M"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
